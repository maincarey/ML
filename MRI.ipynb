{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRI.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maincarey/ML/blob/master/MRI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUOZ-NAjoU_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#root_dir: ./data/\n",
        "#task: either acl, meniscus or abnormal. we'll focus on acl in this post\n",
        "#plane: either sagittal, coronal or axial\n",
        "#train: a boolean variable that indicates whether we are processing train data or not (validation)\n",
        "#transform: the series of data augmentation operations. If None, no data augmentation\n",
        "#weights: custom weights for each class (default to None): this is used to adjust the loss function. When None, weights are computed automatically.\n",
        "\n",
        "#root_dir = '/content/drive/My Drive/AI/Machine Learning/Projects/MRI Prediction Stanford/MRNet-v1.0/'\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.utils.data as data\n",
        "from torchvision import transforms\n",
        "import random\n",
        "#from torchsample.transforms import RandomRotate, RandomTranslate, RandomFlip, ToTensor, Compose, RandomAffine\n",
        "\n",
        "\n",
        "class MRDataset(data.Dataset):\n",
        "    def __init__(self, root_dir, task, plane, train=True, transform=None, weights=None):\n",
        "        super().__init__()\n",
        "        self.task = task\n",
        "        self.plane = plane\n",
        "        self.root_dir = root_dir\n",
        "        self.train = train\n",
        "        if self.train:\n",
        "            self.folder_path = self.root_dir + 'train/{0}/'.format(plane)\n",
        "            self.records = pd.read_csv(\n",
        "                self.root_dir + 'train-{0}.csv'.format(task), header=None, names=['id', 'label'])\n",
        "        else:\n",
        "            transform = None\n",
        "            self.folder_path = self.root_dir + 'valid/{0}/'.format(plane)\n",
        "            self.records = pd.read_csv(\n",
        "                self.root_dir + 'valid-{0}.csv'.format(task), header=None, names=['id', 'label'])\n",
        "\n",
        "        self.records['id'] = self.records['id'].map(\n",
        "            lambda i: '0' * (4 - len(str(i))) + str(i))\n",
        "        self.paths = [self.folder_path + filename +\n",
        "                      '.npy' for filename in self.records['id'].tolist()]\n",
        "        self.labels = self.records['label'].tolist()\n",
        "\n",
        "        self.transform = transform\n",
        "        if weights is None:\n",
        "            pos = np.sum(self.labels)\n",
        "            neg = len(self.labels) - pos\n",
        "            self.weights = torch.FloatTensor([1, neg / pos])\n",
        "        else:\n",
        "            self.weights = torch.FloatTensor(weights)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        array = np.load(self.paths[index])\n",
        "        label = self.labels[index]\n",
        "        if label == 1:\n",
        "            label = torch.FloatTensor([[0, 1]])\n",
        "        elif label == 0:\n",
        "            label = torch.FloatTensor([[1, 0]])\n",
        "\n",
        "        if self.transform:\n",
        "            array = self.transform(array)\n",
        "        else:\n",
        "            array = np.stack((array,)*3, axis=1)\n",
        "            array = torch.FloatTensor(array)\n",
        "\n",
        "        # if label.item() == 1:\n",
        "        #     weight = np.array([self.weights[1]])\n",
        "        #     weight = torch.FloatTensor(weight)\n",
        "        # else:\n",
        "        #     weight = np.array([self.weights[0]])\n",
        "        #     weight = torch.FloatTensor(weight)\n",
        "\n",
        "        return array, label, self.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7eUdgBvoGTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "import argparse\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import keras\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "#from torchsample.transforms import RandomRotate, RandomTranslate, RandomFlip, ToTensor, Compose, RandomAffine\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "from dataloader import MRDataset\n",
        "import model\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, epoch, num_epochs, optimizer, writer, current_lr, log_every=100):\n",
        "    _ = model.train()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "\n",
        "    y_preds = []\n",
        "    y_trues = []\n",
        "    losses = []\n",
        "\n",
        "    for i, (image, label, weight) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            weight = weight.cuda()\n",
        "\n",
        "        label = label[0]\n",
        "        weight = weight[0]\n",
        "\n",
        "        prediction = model.forward(image.float())\n",
        "\n",
        "        loss = torch.nn.BCEWithLogitsLoss(weight=weight)(prediction, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        losses.append(loss_value)\n",
        "\n",
        "        probas = torch.sigmoid(prediction)\n",
        "\n",
        "        y_trues.append(int(label[0][1]))\n",
        "        y_preds.append(probas[0][1].item())\n",
        "\n",
        "        try:\n",
        "            auc = metrics.roc_auc_score(y_trues, y_preds)\n",
        "        except:\n",
        "            auc = 0.5\n",
        "\n",
        "        writer.add_scalar('Train/Loss', loss_value,\n",
        "                          epoch * len(train_loader) + i)\n",
        "        writer.add_scalar('Train/AUC', auc, epoch * len(train_loader) + i)\n",
        "\n",
        "        if (i % log_every == 0) & (i > 0):\n",
        "            print('''[Epoch: {0} / {1} |Single batch number : {2} / {3} ]| avg train loss {4} | train auc : {5} | lr : {6}'''.\n",
        "                  format(\n",
        "                      epoch + 1,\n",
        "                      num_epochs,\n",
        "                      i,\n",
        "                      len(train_loader),\n",
        "                      np.round(np.mean(losses), 4),\n",
        "                      np.round(auc, 4),\n",
        "                      current_lr\n",
        "                  )\n",
        "                  )\n",
        "\n",
        "    writer.add_scalar('Train/AUC_epoch', auc, epoch + i)\n",
        "\n",
        "    train_loss_epoch = np.round(np.mean(losses), 4)\n",
        "    train_auc_epoch = np.round(auc, 4)\n",
        "    return train_loss_epoch, train_auc_epoch\n",
        "\n",
        "\n",
        "def evaluate_model(model, val_loader, epoch, num_epochs, writer, current_lr, log_every=20):\n",
        "    _ = model.eval()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "\n",
        "    y_trues = []\n",
        "    y_preds = []\n",
        "    losses = []\n",
        "\n",
        "    for i, (image, label, weight) in enumerate(val_loader):\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            image = image.cuda()\n",
        "            label = label.cuda()\n",
        "            weight = weight.cuda()\n",
        "\n",
        "        label = label[0]\n",
        "        weight = weight[0]\n",
        "\n",
        "        prediction = model.forward(image.float())\n",
        "\n",
        "        loss = torch.nn.BCEWithLogitsLoss(weight=weight)(prediction, label)\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        losses.append(loss_value)\n",
        "\n",
        "        probas = torch.sigmoid(prediction)\n",
        "\n",
        "        y_trues.append(int(label[0][1]))\n",
        "        y_preds.append(probas[0][1].item())\n",
        "\n",
        "        try:\n",
        "            auc = metrics.roc_auc_score(y_trues, y_preds)\n",
        "        except:\n",
        "            auc = 0.5\n",
        "\n",
        "        writer.add_scalar('Val/Loss', loss_value, epoch * len(val_loader) + i)\n",
        "        writer.add_scalar('Val/AUC', auc, epoch * len(val_loader) + i)\n",
        "\n",
        "        if (i % log_every == 0) & (i > 0):\n",
        "            print('''[Epoch: {0} / {1} |Single batch number : {2} / {3} ] | avg val loss {4} | val auc : {5} | lr : {6}'''.\n",
        "                  format(\n",
        "                      epoch + 1,\n",
        "                      num_epochs,\n",
        "                      i,\n",
        "                      len(val_loader),\n",
        "                      np.round(np.mean(losses), 4),\n",
        "                      np.round(auc, 4),\n",
        "                      current_lr\n",
        "                  )\n",
        "                  )\n",
        "\n",
        "    writer.add_scalar('Val/AUC_epoch', auc, epoch + i)\n",
        "\n",
        "    val_loss_epoch = np.round(np.mean(losses), 4)\n",
        "    val_auc_epoch = np.round(auc, 4)\n",
        "    return val_loss_epoch, val_auc_epoch\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "\n",
        "def run(args):\n",
        "    log_root_folder = \"./logs/{0}/{1}/\".format(args.task, args.plane)\n",
        "    if args.flush_history == 1:\n",
        "        objects = os.listdir(log_root_folder)\n",
        "        for f in objects:\n",
        "            if os.path.isdir(log_root_folder + f):\n",
        "                shutil.rmtree(log_root_folder + f)\n",
        "\n",
        "    now = datetime.now()\n",
        "    logdir = log_root_folder + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "    os.makedirs(logdir)\n",
        "\n",
        "    writer = SummaryWriter(logdir)\n",
        "\n",
        "    \n",
        "    #  will torch work changing \n",
        "    # RandomRotate(25) - to RandomRotation(25)\n",
        "    # RandomFlip() to RandomHorizontalFlip\n",
        "    # RandomTranslate to RandomAffine\n",
        "    \n",
        "    augmentor = Compose([\n",
        "        transforms.Lambda(lambda x: torch.Tensor(x)),\n",
        "        RandomRotation(25),\n",
        "        RandomAffine([0.11, 0.11]),\n",
        "        RandomHorizontalFlip(),\n",
        "        transforms.Lambda(lambda x: x.repeat(3, 1, 1, 1).permute(1, 0, 2, 3)),\n",
        "    ])\n",
        "\n",
        "    # changed file paths\n",
        "    train_dataset = MRDataset('/content/drive/My Drive/AI/Machine Learning/Projects/MRI Prediction Stanford/MRNet-v1.0/', args.task,\n",
        "                              args.plane, transform=augmentor, train=True)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=1, shuffle=True, num_workers=11, drop_last=False)\n",
        "\n",
        "    validation_dataset = MRDataset(\n",
        "        '/content/drive/My Drive/AI/Machine Learning/Projects/MRI Prediction Stanford/MRNet-v1.0/', args.task, args.plane, train=False)\n",
        "    validation_loader = torch.utils.data.DataLoader(\n",
        "        validation_dataset, batch_size=1, shuffle=-True, num_workers=11, drop_last=False)\n",
        "\n",
        "    mrnet = model.MRNet()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        mrnet = mrnet.cuda()\n",
        "\n",
        "    optimizer = optim.Adam(mrnet.parameters(), lr=args.lr, weight_decay=0.1)\n",
        "\n",
        "    if args.lr_scheduler == \"plateau\":\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, patience=3, factor=.3, threshold=1e-4, verbose=True)\n",
        "    elif args.lr_scheduler == \"step\":\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "            optimizer, step_size=3, gamma=args.gamma)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_val_auc = float(0)\n",
        "\n",
        "    num_epochs = args.epochs\n",
        "    iteration_change_loss = 0\n",
        "    patience = args.patience\n",
        "    log_every = args.log_every\n",
        "\n",
        "    t_start_training = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        current_lr = get_lr(optimizer)\n",
        "\n",
        "        t_start = time.time()\n",
        "        \n",
        "        train_loss, train_auc = train_model(\n",
        "            mrnet, train_loader, epoch, num_epochs, optimizer, writer, current_lr, log_every)\n",
        "        val_loss, val_auc = evaluate_model(\n",
        "            mrnet, validation_loader, epoch, num_epochs, writer, current_lr)\n",
        "\n",
        "        if args.lr_scheduler == 'plateau':\n",
        "            scheduler.step(val_loss)\n",
        "        elif args.lr_scheduler == 'step':\n",
        "            scheduler.step()\n",
        "\n",
        "        t_end = time.time()\n",
        "        delta = t_end - t_start\n",
        "\n",
        "        print(\"train loss : {0} | train auc {1} | val loss {2} | val auc {3} | elapsed time {4} s\".format(\n",
        "            train_loss, train_auc, val_loss, val_auc, delta))\n",
        "\n",
        "        iteration_change_loss += 1\n",
        "        print('-' * 30)\n",
        "\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            if bool(args.save_model):\n",
        "                file_name = f'model_{args.prefix_name}_{args.task}_{args.plane}_val_auc_{val_auc:0.4f}_train_auc_{train_auc:0.4f}_epoch_{epoch+1}.pth'\n",
        "                for f in os.listdir('./models/'):\n",
        "                    if (args.task in f) and (args.plane in f) and (args.prefix_name in f):\n",
        "                        os.remove(f'./models/{f}')\n",
        "                torch.save(mrnet, f'./models/{file_name}')\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            iteration_change_loss = 0\n",
        "\n",
        "        if iteration_change_loss == patience:\n",
        "            print('Early stopping after {0} iterations without the decrease of the val loss'.\n",
        "                  format(iteration_change_loss))\n",
        "            break\n",
        "\n",
        "    t_end_training = time.time()\n",
        "    print(f'training took {t_end_training - t_start_training} s')\n",
        "\n",
        "\n",
        "def parse_arguments():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('-t', '--task', type=str, required=True,\n",
        "                        choices=['abnormal', 'acl', 'meniscus'])\n",
        "    parser.add_argument('-p', '--plane', type=str, required=True,\n",
        "                        choices=['sagittal', 'coronal', 'axial'])\n",
        "    parser.add_argument('--prefix_name', type=str, required=True)\n",
        "    parser.add_argument('--augment', type=int, choices=[0, 1], default=1)\n",
        "    parser.add_argument('--lr_scheduler', type=str,\n",
        "                        default='plateau', choices=['plateau', 'step'])\n",
        "    parser.add_argument('--gamma', type=float, default=0.5)\n",
        "    parser.add_argument('--epochs', type=int, default=5)\n",
        "    parser.add_argument('--lr', type=float, default=1e-5)\n",
        "    parser.add_argument('--flush_history', type=int, choices=[0, 1], default=0)\n",
        "    parser.add_argument('--save_model', type=int, choices=[0, 1], default=1)\n",
        "    parser.add_argument('--patience', type=int, default=5)\n",
        "    parser.add_argument('--log_every', type=int, default=100)\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_arguments()\n",
        "    run(args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKrFZkhZoVDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "\n",
        "class MRNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pretrained_model = models.alexnet(pretrained=True)\n",
        "        self.pooling_layer = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifer = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.squeeze(x, dim=0) \n",
        "        features = self.pretrained_model.features(x)\n",
        "        pooled_features = self.pooling_layer(features)\n",
        "        pooled_features = pooled_features.view(pooled_features.size(0), -1)\n",
        "        flattened_features = torch.max(pooled_features, 0, keepdim=True)[0]\n",
        "        output = self.classifer(flattened_features)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19CdejedoVIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}