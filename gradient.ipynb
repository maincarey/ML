{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gradient.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maincarey/ML/blob/master/gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdx8kM_vOLVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gradient decent\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F99eKLYVaPH0",
        "colab_type": "code",
        "outputId": "dee5dcc9-8700-412d-bfd5-e9a01e842f1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "\n",
        "\n",
        "# take the next step in the decent\n",
        "%matplotlib inline\n",
        "\n",
        "def gradient_descent(x,y):\n",
        "    m_curr = b_curr = 0\n",
        "    interations = 10\n",
        "    \n",
        "    # learning rate starting point  start at very low percentage like .001 then increase \n",
        "    # to make sure each iteration the cost is decreasing  when you find global minimun the cost will stay the same\n",
        "    rate = 0.08\n",
        "    \n",
        "    # length of the data point\n",
        "    n = len(x)\n",
        "   # plt.scatter(x,y,color='red',marker='+',linewidth='5')\n",
        "    for i in range(interations):\n",
        "      \n",
        "      # calulate predicetd value of y  m_curr assumption\n",
        "        y_predicted = m_curr * x + b_curr\n",
        "        \n",
        "        # suming all the new points atake the square **2 to deal with the negative values\n",
        "        cost = (1/n) * sum([val**2 for val in (y-y_predicted)])\n",
        "        \n",
        "        print (m_curr,b_curr, i)\n",
        "      #  plt.plot(x,y_predicted,color='green')\n",
        "  \n",
        "  # md derivative\n",
        "        md = -(2/n)*sum(x*(y-y_predicted))\n",
        "        yd = -(2/n)*sum(y-y_predicted)\n",
        "      \n",
        "      # adjust the curr by the learning rate * the partial derivative\n",
        "        m_curr = m_curr - rate * md\n",
        "        b_curr = b_curr - rate * yd\n",
        "        \n",
        "        print (\"m{},b{},cost {}, interation{}\".format(m_curr,b_curr,cost, i))\n",
        "        \n",
        "x = np.array([1,2,3,4,5])\n",
        "y = np.array([5,7,9,11,13])   \n",
        "\n",
        "gradient_descent(x,y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 0\n",
            "m4.96,b1.44,cost 89.0, interation0\n",
            "4.96 1.44 1\n",
            "m0.4991999999999983,b0.26879999999999993,cost 71.10560000000002, interation1\n",
            "0.4991999999999983 0.26879999999999993 2\n",
            "m4.451584000000002,b1.426176000000001,cost 56.8297702400001, interation2\n",
            "4.451584000000002 1.426176000000001 3\n",
            "m0.892231679999997,b0.5012275199999995,cost 45.43965675929613, interation3\n",
            "0.892231679999997 0.5012275199999995 4\n",
            "m4.041314713600002,b1.432759910400001,cost 36.35088701894832, interation4\n",
            "4.041314713600002 1.432759910400001 5\n",
            "m1.2008760606719973,b0.7036872622079998,cost 29.097483330142282, interation5\n",
            "1.2008760606719973 0.7036872622079998 6\n",
            "m3.7095643080294423,b1.4546767911321612,cost 23.307872849944438, interation6\n",
            "3.7095643080294423 1.4546767911321612 7\n",
            "m1.4424862661541864,b0.881337636696883,cost 18.685758762535738, interation7\n",
            "1.4424862661541864 0.881337636696883 8\n",
            "m3.4406683721083144,b1.4879302070713722,cost 14.994867596913156, interation8\n",
            "3.4406683721083144 1.4879302070713722 9\n",
            "m1.6308855378034224,b1.0383405553279617,cost 12.046787238456794, interation9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QQj6UniZ9ZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array([1,2,3,4,5])\n",
        "y = np.array([5,7,9,11,13])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KtN7hvmaKs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gradient_descent(x,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yINk_lgHaW9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# take the next step in the decent\n",
        "def gradient_descent(x,y):\n",
        "   m_curr = b_curr = 0\n",
        "    for i in range(interations):\n",
        "      y_predicted = m_curr * x + b_curr"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}